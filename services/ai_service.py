import asyncio
import base64
import io
import json
import logging
import time
from typing import Any, Dict, List, Optional

import openai
from PIL import Image

from config import Config  # ç¡®ä¿Configå¯ç”¨
from prompts.chinese_prompts import ChinesePrompts
from prompts.english_prompts import EnglishPrompts
from prompts.hindi_prompts import HindiPrompts
from services.knowledge_base import KnowledgeBase


class AIService:
    """AIæœåŠ¡ç±»ï¼Œå¤„ç†æ–‡å­—å’Œå›¾ç‰‡æŸ¥è¯¢"""

    def __init__(self):
        print("ğŸ¤– åˆå§‹åŒ–AIæœåŠ¡...")
        self.config = Config()
        self.logger = logging.getLogger(__name__)

        print("ğŸ”§ åˆå§‹åŒ–APIå®¢æˆ·ç«¯...")

        print(f"âœ… ä½¿ç”¨API: {self.config.TEXT_MODEL}")
        self.client = openai.OpenAI(
            api_key=self.config.AIQIANJI_API_KEY,
            base_url=self.config.AIQIANJI_BASE_URL
        )

        print("ğŸ“š åˆå§‹åŒ–çŸ¥è¯†åº“...")
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        self.knowledge_base = KnowledgeBase()
        self.knowledge_base.load_knowledge_base()

        # å¯¹è¯å†å²ç®¡ç†
        self.conversation_history = []
        self.max_history_length = 10  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯

        print("âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼")

    def add_to_conversation_history(self, role: str, content: str, image_data: Optional[bytes] = None):
        """æ·»åŠ å¯¹è¯åˆ°å†å²è®°å½•"""
        conversation_item = {
            "role": role,
            "content": content,
            "timestamp": time.time(),
            "has_image": image_data is not None
        }

        self.conversation_history.append(conversation_item)

        # ä¿æŒå†å²è®°å½•åœ¨åˆç†é•¿åº¦å†…
        if len(self.conversation_history) > self.max_history_length * 2:  # ç”¨æˆ·å’ŒAIå„ä¸€æ¡
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]

    def get_conversation_context(self) -> str:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        if not self.conversation_history:
            return ""

        context_parts = []
        for item in self.conversation_history[-6:]:  # åªå–æœ€è¿‘6æ¡è®°å½•
            role_name = "ç”¨æˆ·" if item["role"] == "user" else "åŠ©æ‰‹"
            context_parts.append(f"{role_name}: {item['content']}")

        return "\n".join(context_parts)

    def process_text_query(self, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†æ–‡å­—æŸ¥è¯¢"""
        try:
            # ä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¸Šä¸‹æ–‡
            knowledge_context = self.knowledge_base.get_context_for_query(user_question)

            # è·å–å¯¹è¯å†å²ä¸Šä¸‹æ–‡
            conversation_context = self.get_conversation_context()

            # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
            if lang == 'zh':
                prompt_cls = ChinesePrompts
            elif lang == 'en':
                prompt_cls = EnglishPrompts
            elif lang == 'hi':
                prompt_cls = HindiPrompts
            else:
                prompt_cls = ChinesePrompts  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡

            # æ„å»ºæç¤ºè¯ - æ·»åŠ ç”¨æˆ·ä¿¡æ¯
            prompt = prompt_cls.get_prompt_by_type(
                "text_chat",
                user_question=user_question,
                user_info=user_info,  # æ–°å¢ç”¨æˆ·ä¿¡æ¯å‚æ•°
                knowledge_context=knowledge_context,
                conversation_context=conversation_context
            )

            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model=self.config.TEXT_MODEL,
                messages=[
                    {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.config.MAX_TOKENS,
                temperature=self.config.TEMPERATURE,
                extra_body={"chat_template_kwargs": {"thinking": False}}
            )

            answer = response.choices[0].message.content

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.add_to_conversation_history("user", user_question or "")
            self.add_to_conversation_history("assistant", answer or "")

            return {
                "success": True,
                "answer": answer,
                "knowledge_context": knowledge_context,
                "model_used": self.config.TEXT_MODEL,
                "conversation_length": len(self.conversation_history)
            }

        except Exception as e:
            # Log the error for debugging purposes
            print(f"Error processing text query: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "answer": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            }

    def process_image_query(self, image_data: bytes, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†å›¾ç‰‡æŸ¥è¯¢"""
        try:
            # å¤„ç†å›¾ç‰‡
            try:
                image = Image.open(io.BytesIO(image_data))
                if image.format.lower() not in [fmt.strip('.') for fmt in Config.SUPPORTED_IMAGE_FORMATS]:
                    raise ValueError(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {image.format}")
            except Exception as e:
                print(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                return {
                    "success": False,
                    "error": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}",
                    "answer": "æŠ±æ­‰ï¼Œæ— æ³•å¤„ç†æ‚¨ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼æ˜¯å¦æ­£ç¡®"
                }

            # å‹ç¼©å›¾ç‰‡ä»¥ç¬¦åˆAPIè¦æ±‚
            try:
                image = self._resize_image(image)
            except Exception as e:
                print(f"âŒ å›¾ç‰‡å‹ç¼©å¤±è´¥: {str(e)}")
                return {
                    "success": False,
                    "error": f"å›¾ç‰‡å‹ç¼©å¤±è´¥: {str(e)}",
                    "answer": "æŠ±æ­‰ï¼Œå¤„ç†å›¾ç‰‡æ—¶å‡ºç°é”™è¯¯"
                }

            # è½¬æ¢ä¸ºbase64
            try:
                buffered = io.BytesIO()
                image.save(buffered, format="JPEG" if image.format.lower() in ['jpg', 'jpeg'] else image.format)
                img_base64 = base64.b64encode(buffered.getvalue()).decode()
            except Exception as e:
                print(f"âŒ å›¾ç‰‡ç¼–ç å¤±è´¥: {str(e)}")
                return {
                    "success": False,
                    "error": f"å›¾ç‰‡ç¼–ç å¤±è´¥: {str(e)}",
                    "answer": "æŠ±æ­‰ï¼Œå¤„ç†å›¾ç‰‡æ—¶å‡ºç°é”™è¯¯"
                }

            # ä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¸Šä¸‹æ–‡
            knowledge_context = self.knowledge_base.get_context_for_query(user_question)

            # è·å–å¯¹è¯å†å²ä¸Šä¸‹æ–‡
            conversation_context = self.get_conversation_context()

            # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
            if lang == 'zh':
                prompt_cls = ChinesePrompts
            elif lang == 'en':
                prompt_cls = EnglishPrompts
            elif lang == 'hi':
                prompt_cls = HindiPrompts
            else:
                prompt_cls = ChinesePrompts  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡

            # æ ¹æ®è¯­è¨€è®¾ç½®å›¾ç‰‡æè¿°
            image_desc = "ç”¨æˆ·ä¸Šä¼ çš„å•†å“å›¾ç‰‡"
            if lang == 'en':
                image_desc = "User uploaded product image"
            elif lang == 'hi':
                image_desc = "à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¥€ à¤—à¤ˆ à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤›à¤µà¤¿"

            # æ„å»ºæç¤ºè¯ - æ·»åŠ ç”¨æˆ·ä¿¡æ¯
            prompt = prompt_cls.get_prompt_by_type(
                "image_analysis",
                image_description=image_desc,
                user_question=user_question,
                user_info=user_info,  # æ–°å¢ç”¨æˆ·ä¿¡æ¯å‚æ•°
                conversation_context=conversation_context
            )

            # è°ƒç”¨OpenAI Vision API
            response = self.client.chat.completions.create(
                model=self.config.VISION_MODEL,
                messages=[
                    {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{img_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=self.config.MAX_TOKENS,
                temperature=self.config.TEMPERATURE
            )

            answer = response.choices[0].message.content

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.add_to_conversation_history("user", f"{user_question or ''} [å›¾ç‰‡]", image_data)
            self.add_to_conversation_history("assistant", answer or "")

            return {
                "success": True,
                "answer": answer,
                "knowledge_context": knowledge_context,
                "model_used": self.config.VISION_MODEL,
                "image_processed": True,
                "conversation_length": len(self.conversation_history)
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "answer": "æŠ±æ­‰ï¼Œå¤„ç†å›¾ç‰‡æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼æˆ–ç¨åé‡è¯•ã€‚"
            }

    def _resize_image(self, image: Image.Image, max_size: int = 1024) -> Image.Image:
        """è°ƒæ•´å›¾ç‰‡å¤§å°"""
        # è·å–å›¾ç‰‡å°ºå¯¸
        width, height = image.size

        # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼ŒæŒ‰æ¯”ä¾‹ç¼©å°
        if width > max_size or height > max_size:
            if width > height:
                new_width = max_size
                new_height = int(height * max_size / width)
            else:
                new_height = max_size
                new_width = int(width * max_size / height)

            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        return image

    def classify_query_type(self, user_question: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        query_lower = user_question.lower()

        # é€€æ¬¾å”®åç›¸å…³
        if any(keyword in query_lower for keyword in ["é€€æ¬¾", "é€€è´§", "æ¢è´§", "è´¨é‡é—®é¢˜", "åäº†", "ç ´æŸ"]):
            return "after_sales"

        # ç‰©æµç›¸å…³
        if any(keyword in query_lower for keyword in ["ç‰©æµ", "å¿«é€’", "å‘è´§", "é…é€", "ä»€ä¹ˆæ—¶å€™åˆ°", "å¿«é€’å•å·"]):
            return "logistics_query"

        # ä»·æ ¼ä¼˜æƒ ç›¸å…³
        if any(keyword in query_lower for keyword in ["ä»·æ ¼", "ä¼˜æƒ ", "æŠ˜æ‰£", "ä¾¿å®œ", "å¤šå°‘é’±", "ä¼˜æƒ åˆ¸"]):
            return "price_discount"

        # å•†å“æ¨èç›¸å…³
        if any(keyword in query_lower for keyword in ["æ¨è", "å»ºè®®", "ä¹°ä»€ä¹ˆ", "å“ªä¸ªå¥½", "é€‰æ‹©"]):
            return "product_recommendation"

        # é»˜è®¤æ–‡å­—å¯¹è¯
        return "text_chat"

    def get_local_keyword_response(self, user_question: str) -> str:
        """æœ¬åœ°å…³é”®è¯å…œåº•å›å¤"""
        q = user_question.lower()

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹è¯å†å²
        if self.conversation_history:
            last_user_msg = None
            for item in reversed(self.conversation_history):
                if item["role"] == "user":
                    last_user_msg = item["content"]
                    break

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œæä¾›æ›´è¿è´¯çš„å›å¤
            if last_user_msg:
                if "é€€æ¬¾" in q or "é€€è´§" in q:
                    return f"å…³äºæ‚¨æåˆ°çš„é€€æ¬¾/é€€è´§é—®é¢˜ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è¯¦ç»†è¯´æ˜æµç¨‹ï¼š1. åœ¨è®¢å•é¡µé¢ç”³è¯·é€€æ¬¾ 2. è”ç³»å–å®¶åå•† 3. å¦‚æœå–å®¶ä¸åŒæ„ï¼Œå¯ä»¥ç”³è¯·å¹³å°ä»‹å…¥ã€‚æ‚¨æƒ³äº†è§£å“ªä¸ªå…·ä½“æ­¥éª¤ï¼Ÿ"
                elif "ç‰©æµ" in q or "å¿«é€’" in q or "å‘è´§" in q:
                    return f"å…³äºç‰©æµé—®é¢˜ï¼Œè®©æˆ‘ä¸ºæ‚¨è§£ç­”ï¼š1. æ‚¨å¯ä»¥åœ¨è®¢å•é¡µé¢æŸ¥çœ‹ç‰©æµä¿¡æ¯ 2. å¦‚æœé•¿æ—¶é—´æœªå‘è´§ï¼Œå¯ä»¥è”ç³»å–å®¶ 3. å¦‚æœç‰©æµå¼‚å¸¸ï¼Œå¯ä»¥è”ç³»å¿«é€’å…¬å¸ã€‚æ‚¨é‡åˆ°ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼Ÿ"
                elif "ä»·æ ¼" in q or "ä¼˜æƒ " in q or "ä¾¿å®œ" in q:
                    return f"å…³äºä»·æ ¼ä¼˜æƒ ï¼Œæˆ‘å»ºè®®æ‚¨ï¼š1. å…³æ³¨åº—é“ºä¼˜æƒ åˆ¸ 2. å‚ä¸å¹³å°æ´»åŠ¨ 3. ä½¿ç”¨ç§¯åˆ†æŠµæ‰£ 4. ç­‰å¾…ä¿ƒé”€æ´»åŠ¨ã€‚æ‚¨æƒ³äº†è§£å“ªç§ä¼˜æƒ æ–¹å¼ï¼Ÿ"
                elif "æ¨è" in q or "å»ºè®®" in q:
                    return f"æˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„éœ€æ±‚æ¨èå•†å“ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼š1. æ‚¨æƒ³ä¹°ä»€ä¹ˆç±»å‹çš„å•†å“ï¼Ÿ2. æ‚¨çš„é¢„ç®—èŒƒå›´ï¼Ÿ3. æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚å—ï¼Ÿ"

        # é»˜è®¤å›å¤
        if "ä½ å¥½" in q or "æ‚¨å¥½" in q:
            return "æ‚¨å¥½ï¼æˆ‘æ˜¯å¤šè¯­è¨€æ™ºèƒ½å®¢æœï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        elif "é€€æ¬¾" in q or "é€€è´§" in q:
            return "å…³äºé€€æ¬¾/é€€è´§ï¼Œæ‚¨å¯ä»¥ï¼š1. åœ¨è®¢å•é¡µé¢ç”³è¯·é€€æ¬¾ 2. è”ç³»å–å®¶åå•† 3. å¦‚æœå–å®¶ä¸åŒæ„ï¼Œå¯ä»¥ç”³è¯·å¹³å°ä»‹å…¥ã€‚è¯·é—®æ‚¨éœ€è¦å…·ä½“å¸®åŠ©å—ï¼Ÿ"
        elif "ç‰©æµ" in q or "å¿«é€’" in q or "å‘è´§" in q:
            return "å…³äºç‰©æµé—®é¢˜ï¼š1. æ‚¨å¯ä»¥åœ¨è®¢å•é¡µé¢æŸ¥çœ‹ç‰©æµä¿¡æ¯ 2. å¦‚æœé•¿æ—¶é—´æœªå‘è´§ï¼Œå¯ä»¥è”ç³»å–å®¶ 3. å¦‚æœç‰©æµå¼‚å¸¸ï¼Œå¯ä»¥è”ç³»å¿«é€’å…¬å¸ã€‚è¯·é—®æ‚¨é‡åˆ°ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼Ÿ"
        elif "ä»·æ ¼" in q or "ä¼˜æƒ " in q or "ä¾¿å®œ" in q:
            return "å…³äºä»·æ ¼ä¼˜æƒ ï¼š1. å…³æ³¨åº—é“ºä¼˜æƒ åˆ¸ 2. å‚ä¸å¹³å°æ´»åŠ¨ 3. ä½¿ç”¨ç§¯åˆ†æŠµæ‰£ 4. ç­‰å¾…ä¿ƒé”€æ´»åŠ¨ã€‚è¯·é—®æ‚¨æƒ³äº†è§£å“ªç§ä¼˜æƒ æ–¹å¼ï¼Ÿ"
        elif "æ¨è" in q or "å»ºè®®" in q:
            return "æˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„éœ€æ±‚æ¨èå•†å“ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼š1. æ‚¨æƒ³ä¹°ä»€ä¹ˆç±»å‹çš„å•†å“ï¼Ÿ2. æ‚¨çš„é¢„ç®—èŒƒå›´ï¼Ÿ3. æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚å—ï¼Ÿ"
        else:
            return "æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼æˆ‘æ˜¯å¤šè¯­è¨€æ™ºèƒ½å®¢æœï¼Œå¯ä»¥å¸®æ‚¨è§£ç­”ï¼šé€€æ¬¾é€€è´§ã€ç‰©æµé…é€ã€ä»·æ ¼ä¼˜æƒ ã€å•†å“æ¨èç­‰é—®é¢˜ã€‚è¯·é—®æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"

    def is_chitchat_by_model(self, user_question: str) -> bool:
        """ä½¿ç”¨AIæ¨¡å‹åˆ¤æ–­ç”¨æˆ·è¾“å…¥æ˜¯å¦ä¸ºé—²èŠ"""
        try:
            # æ„å»ºé—²èŠåˆ†ç±»æç¤ºè¯
            chat_prompt = f"""è¯·åˆ¤æ–­ç”¨æˆ·è¾“å…¥æ˜¯å¦ä¸ºé—²èŠï¼ˆä¸åšå½©APPæ— å…³çš„é—®å€™ã€å¯’æš„ç­‰ï¼‰ã€‚å¦‚æœæ˜¯é—²èŠè¯·å›å¤"æ˜¯"ï¼Œå¦åˆ™å›å¤"å¦"ã€‚
ç”¨æˆ·è¾“å…¥: {user_question}"""

            response = self.client.chat.completions.create(
                model=self.config.TEXT_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œåªéœ€å›ç­”'æ˜¯'æˆ–'å¦'ã€‚"},
                    {"role": "user", "content": chat_prompt}
                ],
                max_tokens=2,
                temperature=0.0,
                extra_body={"chat_template_kwargs": {"thinking": False}}
            )

            answer = response.choices[0].message.content.strip()
            return answer == "æ˜¯"
        except Exception:
            # æ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°æ£€æµ‹
            q = user_question.strip().lower()
            chitchat_keywords = ["ä½ å¥½", "æ‚¨å¥½", "hi", "hello", "å—¨", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½",
                                "è°¢è°¢", "å¤šè°¢", "æ„Ÿè°¢", "å†è§", "æ‹œæ‹œ", "ok", "å¥½çš„", "çŸ¥é“äº†",
                                "å—¯", "å“¦", "å“ˆå“ˆ", "å˜¿å˜¿"]
            return any(keyword in q for keyword in chitchat_keywords)

    def process_chitchat(self, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†é—²èŠæŸ¥è¯¢ï¼Œä½¿ç”¨å¤§æ¨¡å‹è‡ªç”±å›å¤"""
        try:
            # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
            if lang == 'zh':
                prompt_cls = ChinesePrompts
            elif lang == 'en':
                prompt_cls = EnglishPrompts
            elif lang == 'hi':
                prompt_cls = HindiPrompts
            else:
                prompt_cls = ChinesePrompts  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡

            # æ„å»ºåŒ…å«ç”¨æˆ·ä¿¡æ¯çš„æ¶ˆæ¯
            full_question = f"{user_info}\n{user_question}" if user_info else user_question

            # ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯ä½†ç®€åŒ–ä¸Šä¸‹æ–‡
            messages = [
                {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                {"role": "user", "content": full_question}
            ]

            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model=self.config.TEXT_MODEL,
                messages=messages,
                max_tokens=self.config.MAX_TOKENS,
                temperature=self.config.TEMPERATURE
            )

            answer = response.choices[0].message.content
            return {
                "success": True,
                "answer": answer
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    async def get_enhanced_response(self, user_question: str, image_data: Optional[bytes] = None, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """è·å–å¢å¼ºå›å¤ï¼Œå¤±è´¥æ—¶ç”¨æœ¬åœ°å…³é”®è¯å…œåº•ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºé—²èŠ
            if not image_data and self.is_chitchat_by_model(user_question):
                # å¼‚æ­¥å¤„ç†é—²èŠè¯·æ±‚
                chitchat_result = await self.process_chitchat_async(user_question, lang, user_info)

                if chitchat_result["success"]:
                    answer = chitchat_result["answer"]
                    self.add_to_conversation_history("user", user_question, image_data)
                    self.add_to_conversation_history("assistant", answer)
                    return {
                        "success": True,
                        "answer": answer,
                        "chitchat": True,
                        "model_used": self.config.TEXT_MODEL,
                        "conversation_length": len(self.conversation_history)
                    }
                else:
                    # æ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°å›å¤
                    answer = self.get_local_keyword_response(user_question)
                    self.add_to_conversation_history("user", user_question, image_data)
                    self.add_to_conversation_history("assistant", answer)
                    return {
                        "success": True,
                        "answer": answer,
                        "chitchat": True,
                        "fallback": True,
                        "error": chitchat_result["error"],
                        "conversation_length": len(self.conversation_history)
                    }

            # å¹¶å‘å¤„ç†å›¾ç‰‡å’Œæ–‡æœ¬è¯·æ±‚
            if image_data:
                return await self.process_image_query_async(image_data, user_question, lang, user_info)
            else:
                return await self.process_text_query_async(user_question, lang, user_info)

        except Exception as e:
            # å…œåº•æœ¬åœ°å…³é”®è¯å›å¤
            answer = self.get_local_keyword_response(user_question)
            self.add_to_conversation_history("user", user_question, image_data)
            self.add_to_conversation_history("assistant", answer)
            return {
                "success": True,
                "answer": answer,
                "fallback": True,
                "error": str(e),
                "conversation_length": len(self.conversation_history)
            }

    async def process_text_query_async(self, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¼‚æ­¥å¤„ç†æ–‡å­—æŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯é‡è¯•ï¼‰"""
        # æœ€å¤§é‡è¯•æ¬¡æ•°å’Œåˆå§‹å»¶è¿Ÿ
        max_retries = 3
        retry_delay = 1.0  # åˆå§‹å»¶è¿Ÿ1ç§’

        for attempt in range(max_retries):
            try:
                # å¹¶å‘è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²
                knowledge_context = self.knowledge_base.get_context_for_query(user_question)
                conversation_context = self.get_conversation_context()

                # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
                if lang == 'zh':
                    prompt_cls = ChinesePrompts
                elif lang == 'en':
                    prompt_cls = EnglishPrompts
                elif lang == 'hi':
                    prompt_cls = HindiPrompts
                else:
                    prompt_cls = ChinesePrompts  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡

                # æ„å»ºæç¤ºè¯
                prompt = prompt_cls.get_prompt_by_type(
                    "text_chat",
                    user_question=user_question,
                    user_info=user_info,
                    knowledge_context=knowledge_context,
                    conversation_context=conversation_context
                )

                # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è°ƒç”¨API
                async_client = openai.AsyncOpenAI(
                    api_key=self.config.AIQIANJI_API_KEY,
                    base_url=self.config.AIQIANJI_BASE_URL
                )

                response = await async_client.chat.completions.create(
                    model=self.config.TEXT_MODEL,
                    messages=[
                        {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=self.config.MAX_TOKENS,
                    temperature=self.config.TEMPERATURE
                )

                answer = response.choices[0].message.content

                # æ·»åŠ åˆ°å¯¹è¯å†å²
                self.add_to_conversation_history("user", user_question)
                self.add_to_conversation_history("assistant", answer)

                return {
                    "success": True,
                    "answer": answer,
                    "knowledge_context": knowledge_context,
                    "model_used": self.config.TEXT_MODEL,
                    "conversation_length": len(self.conversation_history)
                }

            except openai.RateLimitError:
                # é€Ÿç‡é™åˆ¶é”™è¯¯ - æŒ‡æ•°é€€é¿
                if attempt < max_retries - 1:
                    delay = retry_delay * (2 ** attempt)
                    print(f"Rate limit exceeded, retrying in {delay:.1f}s (attempt {attempt+1}/{max_retries})")
                    await asyncio.sleep(delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "Rate limit exceeded after retries",
                        "answer": "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
                    }

            except openai.APIConnectionError:
                # è¿æ¥é”™è¯¯ - çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                if attempt < max_retries - 1:
                    print(f"API connection error, retrying in {retry_delay}s (attempt {attempt+1}/{max_retries})")
                    await asyncio.sleep(retry_delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "API connection failed after retries",
                        "answer": "ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•"
                    }

            except Exception as e:
                # å…¶ä»–é”™è¯¯ç›´æ¥è¿”å›
                return {
                    "success": False,
                    "error": str(e),
                    "answer": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                }

    async def process_image_query_async(self, image_data: bytes, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¼‚æ­¥å¤„ç†å›¾ç‰‡æŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯é‡è¯•ï¼‰"""
        max_retries = 3
        retry_delay = 1.0

        for attempt in range(max_retries):
            try:
                # å¤„ç†å›¾ç‰‡ï¼ˆCPUå¯†é›†å‹æ“ä½œï¼Œä¿æŒåŒæ­¥ï¼‰
                image = Image.open(io.BytesIO(image_data))
                image = self._resize_image(image)
                buffered = io.BytesIO()
                image.save(buffered, format="JPEG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode()

                # å¹¶å‘è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²
                knowledge_context = self.knowledge_base.get_context_for_query(user_question)
                conversation_context = self.get_conversation_context()

                # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
                if lang == 'zh':
                    prompt_cls = ChinesePrompts
                elif lang == 'en':
                    prompt_cls = EnglishPrompts
                elif lang == 'hi':
                    prompt_cls = HindiPrompts
                else:
                    prompt_cls = ChinesePrompts

                # æ„å»ºæç¤ºè¯
                image_desc = "ç”¨æˆ·ä¸Šä¼ çš„å•†å“å›¾ç‰‡"
                if lang == 'en':
                    image_desc = "User uploaded product image"
                elif lang == 'hi':
                    image_desc = "à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤…à¤ªà¤²à¥‹à¤¡ à¤•à¥€ à¤—à¤ˆ à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤›à¤µà¤¿"

                prompt = prompt_cls.get_prompt_by_type(
                    "image_analysis",
                    image_description=image_desc,
                    user_question=user_question,
                    user_info=user_info,
                    conversation_context=conversation_context
                )

                # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è°ƒç”¨API
                async_client = openai.AsyncOpenAI(
                    api_key=self.config.AIQIANJI_API_KEY,
                    base_url=self.config.AIQIANJI_BASE_URL
                )

                response = await async_client.chat.completions.create(
                    model=self.config.VISION_MODEL,
                    messages=[
                        {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{img_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens=self.config.MAX_TOKENS,
                    temperature=self.config.TEMPERATURE
                )
                answer = response.choices[0].message.content[0]["text"]

                # æ·»åŠ åˆ°å¯¹è¯å†å²
                self.add_to_conversation_history("user", f"{user_question} [å›¾ç‰‡]", image_data)
                self.add_to_conversation_history("assistant", answer)

                return {
                    "success": True,
                    "answer": answer,
                    "knowledge_context": knowledge_context,
                    "model_used": self.config.VISION_MODEL,
                    "image_processed": True,
                    "conversation_length": len(self.conversation_history)
                }

            except openai.RateLimitError:
                if attempt < max_retries - 1:
                    delay = retry_delay * (2 ** attempt)
                    print(f"Rate limit exceeded, retrying in {delay:.1f}s (attempt {attempt+1}/{max_retries})")
                    await asyncio.sleep(delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "Rate limit exceeded after retries",
                        "answer": "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
                    }

            except openai.APIConnectionError:
                if attempt < max_retries - 1:
                    print(f"API connection error, retrying in {retry_delay}s (attempt {attempt+1}/{max_retries})")
                    await asyncio.sleep(retry_delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "API connection failed after retries",
                        "answer": "ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•"
                    }

            except Exception as e:
                print(f"API connection error, { e}")
                return {
                    "success": False,
                    "error": str(e),
                    "answer": "æŠ±æ­‰ï¼Œå¤„ç†å›¾ç‰‡æ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼æˆ–ç¨åé‡è¯•ã€‚"
                }

    async def process_chitchat_async(self, user_question: str, lang: str = 'zh', user_info: Optional[str] = None) -> Dict[str, Any]:
        """å¼‚æ­¥å¤„ç†é—²èŠæŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯é‡è¯•ï¼‰"""
        max_retries = 2  # é—²èŠè¯·æ±‚ä½¿ç”¨è¾ƒå°‘é‡è¯•æ¬¡æ•°
        retry_delay = 0.5

        for attempt in range(max_retries):
            try:
                # æ ¹æ®è¯­è¨€é€‰æ‹©æç¤ºè¯
                if lang == 'zh':
                    prompt_cls = ChinesePrompts
                elif lang == 'en':
                    prompt_cls = EnglishPrompts
                elif lang == 'hi':
                    prompt_cls = HindiPrompts
                else:
                    prompt_cls = ChinesePrompts

                full_question = f"{user_info}\n{user_question}" if user_info else user_question
                messages = [
                    {"role": "system", "content": prompt_cls.SYSTEM_PROMPT},
                    {"role": "user", "content": full_question}
                ]

                # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è°ƒç”¨API
                async_client = openai.AsyncOpenAI(
                    api_key=self.config.AIQIANJI_API_KEY,
                    base_url=self.config.AIQIANJI_BASE_URL
                )

                response = await async_client.chat.completions.create(
                    model=self.config.TEXT_MODEL,
                    messages=messages,
                    max_tokens=self.config.MAX_TOKENS,
                    temperature=self.config.TEMPERATURE
                )

                answer = response.choices[0].message.content
                return {
                    "success": True,
                    "answer": answer
                }

            except openai.RateLimitError:
                if attempt < max_retries - 1:
                    delay = retry_delay * (2 ** attempt)
                    await asyncio.sleep(delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "Rate limit exceeded"
                    }

            except openai.APIConnectionError:
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "API connection failed"
                    }

            except Exception as e:
                return {
                    "success": False,
                    "error": str(e)
                }

    def clear_conversation_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        return {"success": True, "message": "å¯¹è¯å†å²å·²æ¸…ç©º"}

    def detect_language(self, text: str) -> str:
        """æ£€æµ‹æ–‡æœ¬çš„è¯­è¨€

        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬

        Returns:
            è¯­è¨€ä»£ç  (zh, en, hi) æˆ– 'en' ä½œä¸ºé»˜è®¤å€¼
        """
        try:
            lang = self._detect_language_with_model(text)
            return lang
        except Exception as e:
            self.logger.error(f"è¯­è¨€æ£€æµ‹å¤±è´¥: {str(e)}")
            return 'en'

    def _detect_language_with_model(self, text: str) -> str:
        """ä½¿ç”¨å¤§æ¨¡å‹æ£€æµ‹è¯­è¨€"""
        try:
            # ç³»ç»Ÿæç¤ºè¯
            system_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªè¯­è¨€æ£€æµ‹å™¨ã€‚è¯·åˆ†æç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œå¹¶è¿”å›å¯¹åº”çš„è¯­è¨€ä»£ç ï¼š\n"
                "zh=ä¸­æ–‡, en=è‹±æ–‡, hi=å°åœ°è¯­ã€‚å…¶ä»–è¯­è¨€è¿”å›'en'ã€‚åªè¿”å›è¯­è¨€ä»£ç ã€‚"
            )

            response = self.client.chat.completions.create(
                model=self.config.TEXT_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=5,
                temperature=0.0
            )

            answer = response.choices[0].message.content.strip().lower()

            # éªŒè¯è¿”å›ç»“æœ
            if answer in ['zh', 'en', 'hi']:
                return answer
            return 'en'  # é»˜è®¤è¿”å›è‹±æ–‡
        except Exception as e:
            self.logger.error(f"æ¨¡å‹è¯­è¨€æ£€æµ‹å¤±è´¥: {str(e)}")
            return 'en'

    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        if not self.conversation_history:
            return {"success": True, "summary": "æš‚æ— å¯¹è¯è®°å½•"}

        try:
            # ç»Ÿè®¡å¯¹è¯ä¿¡æ¯
            user_messages = [msg for msg in self.conversation_history if msg["role"] == "user"]
            assistant_messages = [msg for msg in self.conversation_history if msg["role"] == "assistant"]

            summary = {
                "total_messages": len(self.conversation_history),
                "user_messages": len(user_messages),
                "assistant_messages": len(assistant_messages),
                "conversation_duration": self.conversation_history[-1]["timestamp"] - self.conversation_history[0]["timestamp"] if len(self.conversation_history) > 1 else 0,
                "topics": self._extract_topics()
            }

            return {"success": True, "summary": summary}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _extract_topics(self) -> List[str]:
        """æå–å¯¹è¯ä¸»é¢˜"""
        topics = []
        all_content = " ".join([msg["content"] for msg in self.conversation_history])

        # ç®€å•çš„å…³é”®è¯æå–
        keywords = {
            "é€€æ¬¾é€€è´§": ["é€€æ¬¾", "é€€è´§", "æ¢è´§", "è´¨é‡é—®é¢˜"],
            "ç‰©æµé…é€": ["ç‰©æµ", "å¿«é€’", "å‘è´§", "é…é€"],
            "ä»·æ ¼ä¼˜æƒ ": ["ä»·æ ¼", "ä¼˜æƒ ", "æŠ˜æ‰£", "ä¾¿å®œ"],
            "å•†å“æ¨è": ["æ¨è", "å»ºè®®", "ä¹°ä»€ä¹ˆ", "é€‰æ‹©"]
        }

        for topic, words in keywords.items():
            if any(word in all_content for word in words):
                topics.append(topic)

        return topics

    def add_to_knowledge_base(self, question: str, answer: str, category: str = "custom"):
        """æ·»åŠ æ–°çŸ¥è¯†åˆ°çŸ¥è¯†åº“"""
        try:
            self.knowledge_base.add_custom_knowledge(
                content=f"é—®é¢˜ï¼š{question}\nç­”æ¡ˆï¼š{answer}",
                knowledge_type="custom",
                category=category,
                question=question,
                answer=answer
            )
            return {"success": True, "message": "çŸ¥è¯†å·²æ·»åŠ åˆ°çŸ¥è¯†åº“"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def search_knowledge_base(self, query: str, top_k: int = 5):
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            results = self.knowledge_base.search(query, top_k)
            return {"success": True, "results": results}
        except Exception as e:
            return {"success": False, "error": str(e)}